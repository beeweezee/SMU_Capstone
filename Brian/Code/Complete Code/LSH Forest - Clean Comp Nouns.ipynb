{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datasketch import MinHash, MinHashLSHForest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import model_report as mr\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = \"C:\\\\Users\\\\blgai\\\\OneDrive\\\\Documents\\\\School\\\\SMU\\\\Courses\\\\Fall 2021\\\\Capstone A\\Data\\\\cleaned_chunked_v2.csv\"\n",
    "df = pd.read_csv(file_info, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance classes\n",
    "g = df.groupby('category')\n",
    "df = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>key_words</th>\n",
       "      <th>content</th>\n",
       "      <th>combined</th>\n",
       "      <th>nouns</th>\n",
       "      <th>compounds</th>\n",
       "      <th>comp_nouns</th>\n",
       "      <th>flat_comp_nouns</th>\n",
       "      <th>clean_comp_nouns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bu</th>\n",
       "      <th>0</th>\n",
       "      <td>*://ATS-SERVER.DE</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>ADAMCO INC - Houston, Texas</td>\n",
       "      <td>Adamco Technology Services is providing Consul...</td>\n",
       "      <td>HIGH STRENGTH, ALUMINUM alloys, Aeronautics, A...</td>\n",
       "      <td>Home US site Contact Welcome to ADAMCO Technol...</td>\n",
       "      <td>ADAMCO INC - Houston, Texas Adamco Technology ...</td>\n",
       "      <td>[('ADAMCO', 0, 6, 'PROPN'), ('INC', 7, 10, 'PR...</td>\n",
       "      <td>[('ADAMCO INC -', 0, 12, 'COMPOUND'), ('Texas ...</td>\n",
       "      <td>{'modulus', 'Rights Reserved', 'ADAMCO Technol...</td>\n",
       "      <td>{'modulus', 'Rights Reserved', 'ADAMCO Technol...</td>\n",
       "      <td>modulus rights reserved adamco technology serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*://feanalytics.com</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>FE Analytics | Online Fund Research Tool</td>\n",
       "      <td>An award winning online financial planning too...</td>\n",
       "      <td>fe analytics, fund research, financial plannin...</td>\n",
       "      <td>FE Analytics Login Home 10 Years Features Abou...</td>\n",
       "      <td>FE Analytics | Online Fund Research Tool An aw...</td>\n",
       "      <td>[('FE', 0, 2, 'PROPN'), ('Analytics', 3, 12, '...</td>\n",
       "      <td>[('FE Analytics |', 0, 14, 'COMPOUND'), ('Onli...</td>\n",
       "      <td>{'Years', 'FE', 'Testimonials Testimonials Cas...</td>\n",
       "      <td>{'Years', 'FE', 'Testimonials Testimonials Cas...</td>\n",
       "      <td>years fe testimonial testimonials case studies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*://SEARECOVERY.COM</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>Sea Recovery Global - Welcome</td>\n",
       "      <td>Sea Recovery is a global provider of marine an...</td>\n",
       "      <td>marine watermakers, reverse osmosis systems, w...</td>\n",
       "      <td>Welcome to Sea Recovery Global | The World's L...</td>\n",
       "      <td>Sea Recovery Global - Welcome Sea Recovery is ...</td>\n",
       "      <td>[('Sea', 0, 3, 'PROPN'), ('Recovery', 4, 12, '...</td>\n",
       "      <td>[('Recovery Global -', 0, 17, 'COMPOUND'), ('G...</td>\n",
       "      <td>{'Ideal', 'CAPACITY', 'boat', 'Tons', 'World',...</td>\n",
       "      <td>{'Ideal', 'CAPACITY', 'boat', 'Tons', 'World',...</td>\n",
       "      <td>ideal capacity boat tons world watermaker mega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*://WWW.DTIDC.IN</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>Delhi Transport Infrastructure Development Cor...</td>\n",
       "      <td>Delhi Transport Infrastructure Development Cor...</td>\n",
       "      <td>Dtidc, DTIDC</td>\n",
       "      <td>Our Services Interstate Bus Terminals Bus Que ...</td>\n",
       "      <td>Delhi Transport Infrastructure Development Cor...</td>\n",
       "      <td>[('Delhi', 0, 5, 'PROPN'), ('Transport', 6, 15...</td>\n",
       "      <td>[('Delhi Transport Infrastructure Development ...</td>\n",
       "      <td>{'Team', 'Maharana', 'stands', 'e', 'Executive...</td>\n",
       "      <td>{'Team', 'Maharana', 'stands', 'e', 'Executive...</td>\n",
       "      <td>team maharana stand e executive flow kashmiri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*://CUSTOMSEALANDRUBBER.COM</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>Welcome to Custom Seal and Rubber Products! | ...</td>\n",
       "      <td>Custom Seal and Rubber Products specializes in...</td>\n",
       "      <td>poly, seal, rubber, polyurethane, custom, prod...</td>\n",
       "      <td>Navigation Home Molding Polyurethane Silicone ...</td>\n",
       "      <td>Welcome to Custom Seal and Rubber Products! | ...</td>\n",
       "      <td>[('Custom', 11, 17, 'PROPN'), ('Seal', 18, 22,...</td>\n",
       "      <td>[('Custom Seal', 11, 22, 'COMPOUND'), ('Rubber...</td>\n",
       "      <td>{'Flexibility', 'precision', 'die cut', 'Syste...</td>\n",
       "      <td>{'Flexibility', 'precision', 'die cut', 'Syste...</td>\n",
       "      <td>flexibility precision die cut systems register...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    url  code category language  \\\n",
       "category                                                          \n",
       "bu       0            *://ATS-SERVER.DE   200       bu       en   \n",
       "         1          *://feanalytics.com   200       bu       en   \n",
       "         2          *://SEARECOVERY.COM   200       bu       en   \n",
       "         3             *://WWW.DTIDC.IN   200       bu       en   \n",
       "         4  *://CUSTOMSEALANDRUBBER.COM   200       bu       en   \n",
       "\n",
       "                                                        title  \\\n",
       "category                                                        \n",
       "bu       0                        ADAMCO INC - Houston, Texas   \n",
       "         1           FE Analytics | Online Fund Research Tool   \n",
       "         2                      Sea Recovery Global - Welcome   \n",
       "         3  Delhi Transport Infrastructure Development Cor...   \n",
       "         4  Welcome to Custom Seal and Rubber Products! | ...   \n",
       "\n",
       "                                                      summary  \\\n",
       "category                                                        \n",
       "bu       0  Adamco Technology Services is providing Consul...   \n",
       "         1  An award winning online financial planning too...   \n",
       "         2  Sea Recovery is a global provider of marine an...   \n",
       "         3  Delhi Transport Infrastructure Development Cor...   \n",
       "         4  Custom Seal and Rubber Products specializes in...   \n",
       "\n",
       "                                                    key_words  \\\n",
       "category                                                        \n",
       "bu       0  HIGH STRENGTH, ALUMINUM alloys, Aeronautics, A...   \n",
       "         1  fe analytics, fund research, financial plannin...   \n",
       "         2  marine watermakers, reverse osmosis systems, w...   \n",
       "         3                                       Dtidc, DTIDC   \n",
       "         4  poly, seal, rubber, polyurethane, custom, prod...   \n",
       "\n",
       "                                                      content  \\\n",
       "category                                                        \n",
       "bu       0  Home US site Contact Welcome to ADAMCO Technol...   \n",
       "         1  FE Analytics Login Home 10 Years Features Abou...   \n",
       "         2  Welcome to Sea Recovery Global | The World's L...   \n",
       "         3  Our Services Interstate Bus Terminals Bus Que ...   \n",
       "         4  Navigation Home Molding Polyurethane Silicone ...   \n",
       "\n",
       "                                                     combined  \\\n",
       "category                                                        \n",
       "bu       0  ADAMCO INC - Houston, Texas Adamco Technology ...   \n",
       "         1  FE Analytics | Online Fund Research Tool An aw...   \n",
       "         2  Sea Recovery Global - Welcome Sea Recovery is ...   \n",
       "         3  Delhi Transport Infrastructure Development Cor...   \n",
       "         4  Welcome to Custom Seal and Rubber Products! | ...   \n",
       "\n",
       "                                                        nouns  \\\n",
       "category                                                        \n",
       "bu       0  [('ADAMCO', 0, 6, 'PROPN'), ('INC', 7, 10, 'PR...   \n",
       "         1  [('FE', 0, 2, 'PROPN'), ('Analytics', 3, 12, '...   \n",
       "         2  [('Sea', 0, 3, 'PROPN'), ('Recovery', 4, 12, '...   \n",
       "         3  [('Delhi', 0, 5, 'PROPN'), ('Transport', 6, 15...   \n",
       "         4  [('Custom', 11, 17, 'PROPN'), ('Seal', 18, 22,...   \n",
       "\n",
       "                                                    compounds  \\\n",
       "category                                                        \n",
       "bu       0  [('ADAMCO INC -', 0, 12, 'COMPOUND'), ('Texas ...   \n",
       "         1  [('FE Analytics |', 0, 14, 'COMPOUND'), ('Onli...   \n",
       "         2  [('Recovery Global -', 0, 17, 'COMPOUND'), ('G...   \n",
       "         3  [('Delhi Transport Infrastructure Development ...   \n",
       "         4  [('Custom Seal', 11, 22, 'COMPOUND'), ('Rubber...   \n",
       "\n",
       "                                                   comp_nouns  \\\n",
       "category                                                        \n",
       "bu       0  {'modulus', 'Rights Reserved', 'ADAMCO Technol...   \n",
       "         1  {'Years', 'FE', 'Testimonials Testimonials Cas...   \n",
       "         2  {'Ideal', 'CAPACITY', 'boat', 'Tons', 'World',...   \n",
       "         3  {'Team', 'Maharana', 'stands', 'e', 'Executive...   \n",
       "         4  {'Flexibility', 'precision', 'die cut', 'Syste...   \n",
       "\n",
       "                                              flat_comp_nouns  \\\n",
       "category                                                        \n",
       "bu       0  {'modulus', 'Rights Reserved', 'ADAMCO Technol...   \n",
       "         1  {'Years', 'FE', 'Testimonials Testimonials Cas...   \n",
       "         2  {'Ideal', 'CAPACITY', 'boat', 'Tons', 'World',...   \n",
       "         3  {'Team', 'Maharana', 'stands', 'e', 'Executive...   \n",
       "         4  {'Flexibility', 'precision', 'die cut', 'Syste...   \n",
       "\n",
       "                                             clean_comp_nouns  \n",
       "category                                                       \n",
       "bu       0  modulus rights reserved adamco technology serv...  \n",
       "         1  years fe testimonial testimonials case studies...  \n",
       "         2  ideal capacity boat tons world watermaker mega...  \n",
       "         3  team maharana stand e executive flow kashmiri ...  \n",
       "         4  flexibility precision die cut systems register...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "bu    1595\n",
       "dr    1595\n",
       "ed    1595\n",
       "mk    1595\n",
       "os    1595\n",
       "sp    1595\n",
       "sx    1595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df.category).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7812,), (2236,), (1117,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#get 10% holdout set\n",
    "train_corpus, holdout_corpus, train_label, holdout_label = train_test_split(df['clean_comp_nouns'], \n",
    "                                                                           df['category'],\n",
    "                                                                           test_size=.10,random_state=1234)\n",
    "\n",
    "#get 80% train and 20% test sets\n",
    "train_corpus, test_corpus, train_label, test_label = train_test_split(train_corpus,\n",
    "                                                                      train_label,\n",
    "                                                                      test_size=.2225,random_state=1234) #.9 * .2225 = .20\n",
    "\n",
    "train_corpus.shape, test_corpus.shape, holdout_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(zip(train_corpus,train_label),columns=[\"clean_comp_nouns\",\"label\"])\n",
    "df_test = pd.DataFrame(zip(test_corpus,test_label),columns=[\"clean_comp_nouns\",\"label\"])\n",
    "df_holdout = pd.DataFrame(zip(holdout_corpus,holdout_label),columns=[\"clean_comp_nouns\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comp_nouns</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resource world social industry network target ...</td>\n",
       "      <td>bu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baby vertical mount bed vegetables flowers org...</td>\n",
       "      <td>os</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>address faq check email address cancel post pr...</td>\n",
       "      <td>mk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rohre germany sales beteiligten von produktion...</td>\n",
       "      <td>bu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>industry robert f kennedy tar sand robert home...</td>\n",
       "      <td>bu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    clean_comp_nouns label\n",
       "0  resource world social industry network target ...    bu\n",
       "1  baby vertical mount bed vegetables flowers org...    os\n",
       "2  address faq check email address cancel post pr...    mk\n",
       "3  rohre germany sales beteiligten von produktion...    bu\n",
       "4  industry robert f kennedy tar sand robert home...    bu"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Permutations\n",
    "permutations = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    tokens = text.lower()\n",
    "    tokens = tokens.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forest(data,perms):\n",
    "    start_time = time.time()\n",
    "    minhash = []\n",
    "    for text in data['clean_comp_nouns']:\n",
    "        tokens = preprocess(text)\n",
    "        m = MinHash(num_perm=perms)\n",
    "        for s in tokens:\n",
    "            m.update(s.encode('utf8'))\n",
    "        minhash.append(m)\n",
    "        \n",
    "    forest = MinHashLSHForest(num_perm=perms)\n",
    "    \n",
    "    for i,m in enumerate(minhash):\n",
    "        forest.add(i,m)\n",
    "    \n",
    "    forest.index()\n",
    "    \n",
    "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(list1,list2):\n",
    "    from collections import Counter\n",
    "\n",
    "    # count word occurrences\n",
    "    a_vals = Counter(list1)\n",
    "    b_vals = Counter(list2)\n",
    "\n",
    "    # convert to word-vectors\n",
    "    words  = list(a_vals.keys() | b_vals.keys())\n",
    "    a_vect = [a_vals.get(word, 0) for word in words]        \n",
    "    b_vect = [b_vals.get(word, 0) for word in words]        \n",
    "\n",
    "    # find cosine\n",
    "    len_a  = sum(av*av for av in a_vect) ** 0.5             \n",
    "    len_b  = sum(bv*bv for bv in b_vect) ** 0.5             \n",
    "    dot    = sum(av*bv for av,bv in zip(a_vect, b_vect))    \n",
    "    cosine = dot / (len_a * len_b)                          \n",
    "    \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(test_item, database, perms, num_results, forest):\n",
    "        \n",
    "    tokens = preprocess(test_item)\n",
    "    m = MinHash(num_perm=perms)\n",
    "    for s in tokens:\n",
    "        m.update(s.encode('utf8'))\n",
    "    \n",
    "    idx_array = np.array(forest.query(m, num_results))\n",
    "    if len(idx_array) == 0:\n",
    "        return None #if query is empty, return none\n",
    "    \n",
    "    #label = database.iloc[idx_array]['label']\n",
    "    #text = database.iloc[idx_array]['clean_comp_nouns']\n",
    "    df_results = pd.DataFrame(database.iloc[idx_array][['clean_comp_nouns','label']])\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_item, database, perms, num_results, forest):\n",
    "    df_pred = get_similars(test_item,df_train,permutations,num_similars,forest)\n",
    "    df_pred['cos_dist'] = df_pred.apply(lambda x: get_cosine(preprocess(x['clean_comp_nouns']),text),axis=1)\n",
    "    \n",
    "    return df_pred.sort_values('cos_dist',ascending=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(test_item, database, perms, num_results, forest):\n",
    "    df_pred_one = predict(test_item, database, perms, num_results, forest)\n",
    "    #get most similar item based on cosine distance\n",
    "    cat = None\n",
    "    try:\n",
    "        cat = df_pred_one.iloc[1, 1]\n",
    "    except:\n",
    "        cat = 'ed'\n",
    "    \n",
    "    return cat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mod(test_item, database, perms, num_results, forest):\n",
    "    label = None\n",
    "    try:\n",
    "        df_pred_mod = get_similars(test_item,df_train,permutations,num_similars,forest)\n",
    "        label = df_pred_mod['label'].value_counts()[:1].index.tolist()[0]\n",
    "    except:\n",
    "        return None\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 62.27829074859619 seconds to build forest.\n"
     ]
    }
   ],
   "source": [
    "#build lsh forest using training data\n",
    "forest = get_forest(df_train,permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual label:  ed\n",
      "mod similar:  dr\n",
      "closest similar:  dr\n",
      "All similars:                                         clean_comp_nouns label  cos_dist\n",
      "2386  smartpac smartpacglandpackings nd stem rings w...    bu  0.109114\n",
      "342   un prochain eveneman faq montreal dans votre c...    dr  0.039704\n",
      "176   space function motility citrus aurantium extra...    dr  0.033715\n",
      "1106  cupidus seedling hills palmtree sphagnum livis...    mk  0.028030\n",
      "449   v messages pls samuel compilers libraries math...    bu  0.026426\n",
      "2591  smooth bpx dotmatrix feeders memory networking...    os  0.025162\n",
      "4033  orchids thorns order aroids alocasia heliampho...    os  0.024658\n",
      "6265  address strain cultivator sensi seeds pablo ma...    dr  0.021162\n",
      "4483  address strain cultivator sensi seeds pablo ma...    dr  0.021023\n",
      "4706  street purple lady cab mdma procaine lab test ...    dr  0.020988\n",
      "2075  street purple lady cab mdma procaine lab test ...    dr  0.020988\n",
      "941   bealeii airy shrub invincibelle spirit pp pink...    os  0.020125\n",
      "1474  basket espejo compra gears tu contrasena l lau...    os  0.018858\n",
      "5193  rights reserved wicca view cart e faq willowro...    os  0.016431\n",
      "3361  hills network san fernando california state co...    mk  0.016068\n",
      "7281  reviews pinkoyster pleurotus djamor pink oyste...    dr  0.014822\n",
      "5309  talent show tryouts history open houses gem mi...    sp  0.012277\n",
      "5817  pressure sodium bulb light mover pulleys enjoy...    dr  0.009210\n",
      "5367  year bloom latest blog news service form garde...    mk  0.008112\n",
      "4772  world cannaventure super top tao seeds tropica...    dr  0.007637\n",
      "4059  rights reserved enjoyment naturist function ex...    sx  0.007569\n",
      "4538  reviews rights reserved strain spores cart ear...    dr  0.007198\n",
      "5167  rights reserved strain cannabis art bulk ogr f...    dr  0.006660\n",
      "4657  scenario scouting year coatesville winter coll...    sp  0.006293\n",
      "4028  world deal poundsterling gbp canadian dollar n...    dr  0.005520\n",
      "3467  world deal poundsterling gbp canadian dollar n...    dr  0.005514\n",
      "576   review barneysfarm chunk channel world mandala...    dr  0.005448\n",
      "1525  rights reserved strain cannabis art bulk cvt e...    dr  0.005182\n",
      "1113  stripper sarah vandella shemale escorts new je...    sx  0.004979\n",
      "4106  vulkania seeds chunk world cannaventure krippl...    dr  0.004484\n",
      "5104  basket vulkania seeds world industry cannavent...    dr  0.004294\n",
      "6302  vulkania seeds chunk world cannaventure krippl...    dr  0.003642\n",
      "2010  reviews address drainage history strain top ma...    dr  0.001964\n",
      "126   rights reserved president history linkedin guc...    ed  0.001189\n",
      "7184  baby live wood frame pattern choice faq owl na...    os  0.000500\n",
      "2079  world strain super azura seed climate jah deli...    dr  0.000266\n",
      "3028  petroleum grinder gasoline history glories cra...    dr  0.000152\n",
      "1618  basket pink blush freshflowers phalaenopsis or...    mk  0.000102\n",
      "759   world marijuana seeds gallery marijuana seeds ...    dr  0.000031\n",
      "385   basket coupons reviews corporate gifting corpo...    os  0.000015\n",
      "217   underestimateii medicines price policy underes...    dr  0.000000\n",
      "7230  year entry promo females magnus bucks programs...    sx  0.000000\n",
      "2494  basket uk prom daisy interflora member favouri...    os  0.000000\n",
      "1596  reviews serve cart mid century itsy kingdom ju...    os  0.000000\n",
      "3676  published articles plant library christmas cac...    os  0.000000\n",
      "2992  insurance company woodland hill truck accident...    bu  0.000000\n",
      "7787  rights reserved template chatfield award indus...    mk  0.000000\n",
      "667   year agent orange carpe grove industry pacific...    dr  0.000000\n",
      "7063  industry wind insurance solarinsure solarinsur...    bu  0.000000\n",
      "5527  baby basket felpham function winter master car...    os  0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'resource schuylkill center facebook twitter instagram rights reserved native history bird watcher team building programs wildlife fund exhibits water art program scee butterfly house exelon gifts haas trustees staff partnerships resources seedlings view detour birding departments nature preschool teacher membership toad paper peco trust geology jdb pa parent child fun green field exhibit us reptile envirothon rights initiatives resource conservation service problem museum service wellness game party art peco energy scout fees simpson paper company challenge trail panels season education amphitheater penn squirrel philadelphia envirothon overview competition topics past winners water department health camp haas company summer camp conservation association gardener center naturalist birds appreciation delaware kind birthday party bureau mclean rohm park commission gardener gallery workshop land past roxborough review pa department nature lover kindergarten teachers registration preservation studies summer fax program twitter land conservation philadelphia student district support camp matching topics free overview hiking trails exhibits overview discovery center green roof solar panels art gallery gift shop pavilion bloom calendar join clinic rental program facilities join organic garden membership foundation badges protection tribute gifts day adult barra team faq property agriculture building bird pond partner estuary geologist lecture environmental education contact studios fun us overview conservation easements maps girl scout grades horace goldsmith foundation rehab overview sceemyschool park policy phillie laboratory gardener use donatenow educator land restoration club wissahickon reservation butterfly house volunteer opportunity donate membership annual appeal matching gifts restoration emergeny alliance forestry hike service birthday society hours mill road teen commission operation history board scee spotting sites join birding list challenge course watcher ecosystem monitoring mammal involvement bird club energy upcoming picnic pa fish camps boy pa museum summer online sept view submission opportunities landlab program events blog nature preschool staff news trustees university nature resources serve department boat landlab william research teacher environment partnerships facebook roxborough protection agency supplements wildlife child map weekly news new port royal avenue lifestyle campaign development marketing tree baby gorgas william penn foundation email newsletter river greenway association ecology hiking privacy volunteer service horace conservation garden site school reservation kind wishlist appeal www tuscanostudios com wildlife rehab clinic boy scout nature center land preservation student water monitoring network tuition challenge teachers overview professional development curriculum supplements graduate programs art sign institute guide parent port camp avenue roof u privacy policy tuscano tract donation schuylkill center preschool sign october student schools community affair board birding stewardship widener team join yoga participants property september volunteer email marketing jobs email girl site forms scee overview birds camps email astronomer wildlife center bird humanity cook rabbit master faqs search facilities pa game commission wright form schuylkill wright solar amphibian tigers community spotting barra foundation boat commission discounted programs center situations participants scouting overview girl scouts overview boy scouts overview tigers hike parent boy community staff james arcadia foundation operation lifestyle emergeny situations copyright school program forest hagy donatenow property contributionship environmental art overview competition village gift road overview bird baby bird adult mammal baby rabbit baby squirrel baby mammal reptile art information opportunity richard l james lecture birder faqs fees merit badges summer camp day building professional wishlist copyright schuylkill center verizon l garden webelos bloom event trust forest year yoga retreat detour programs arcadia opportunities enchanted discovery trails education adults partnership sites picnic child purpose fall walk info tuscano studios pa audubon society discounted reserved butterfly online donation form event volunteer opportunities search registration forms field trip registration scee hiking ways winners blog field delaware estuary school affair organic environmental directions toad ecovan restoration camp campaign environmental education wildlife clinic bird graduate school district health donate understanding pond mill newsworks pa master naturalist program challenge course shop team building philadelphia phillie program school submission newsletter wildlife clinic wildlife programs land restoration overview restoration sites research studies new initiatives gardener upcoming event enchanted forest teacher workshops neducsin guide native plants review company overview faq curriculum facility sceeschuylkillcenter org wildlife clinic list weather philadelphia day friend greenway neducsin property instagram people contact issue river wright cook foundation richard course wildlife clinic improvement overview birthday parties high ropes challenge course parties animal scouting high wood course girl usda merit phone pennsylvania ropes birthday library simpson party whyy royal art exhibit list serve organic community garden network lover pavilion response mission cubs scouts rental birthday party plant connection amphibian support audubon calendar fish blog departments overview tribute clinic land trip nature preschool programs easement gorgas park retreat community goldsmith reptile agency cubs webelos environmental education annual'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of similars to return\n",
    "num_similars = 50\n",
    "test_item = 5\n",
    "text = df_test['clean_comp_nouns'][test_item]\n",
    "#query the forest\n",
    "df_predict = predict(text,df_train,permutations,num_similars,forest)\n",
    "print('actual label: ',df_test['label'][test_item])\n",
    "print('mod similar: ',predict_mod(text,df_train,permutations,num_similars,forest))\n",
    "print('closest similar: ',predict_one(text,df_train,permutations,num_similars,forest))\n",
    "print('All similars: ',predict(text,df_train,permutations,num_similars,forest))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(list(zip(df_test['clean_comp_nouns'],df_test['label'])),columns=['terms','category'])\n",
    "df_results['lsh_predict'] = df_results.apply(lambda x: predict_mod(x['terms'],df_train,permutations,num_similars,forest),axis=1)\n",
    "df_results['match'] = np.where(df_results['category']==df_results['lsh_predict'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>category</th>\n",
       "      <th>lsh_predict</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>mabuya angularis phelsumania tail lowland abbo...</td>\n",
       "      <td>ed</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>sexfilme sexfilme amateursex amateurporno amat...</td>\n",
       "      <td>sx</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 terms category lsh_predict  \\\n",
       "347  mabuya angularis phelsumania tail lowland abbo...       ed        None   \n",
       "777  sexfilme sexfilme amateursex amateurporno amat...       sx        None   \n",
       "\n",
       "     match  \n",
       "347      0  \n",
       "777      0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['lsh_predict'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalSamples': 2236,\n",
       " 'overallAccuracy': 0.49105545617173524,\n",
       " 'byCategory': {'sx': {'totalSamples': 332, 'accuracy': 0.8162650602409639},\n",
       "  'dr': {'totalSamples': 331, 'accuracy': 0.6827794561933535},\n",
       "  'sp': {'totalSamples': 318, 'accuracy': 0.44339622641509435},\n",
       "  'ed': {'totalSamples': 330, 'accuracy': 0.43333333333333335},\n",
       "  'os': {'totalSamples': 314, 'accuracy': 0.40764331210191085},\n",
       "  'bu': {'totalSamples': 311, 'accuracy': 0.3440514469453376},\n",
       "  'mk': {'totalSamples': 300, 'accuracy': 0.2733333333333333}}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpt = mr.generate_report(df_results)\n",
    "rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(df_results['category'],df_results['lsh_predict'],labels=['os','ed','dr','sp','mk','sx','bu'])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "mr.plot_confusion_matrix(cnf_matrix, classes=['os','ed','dr','sp','mk','sx','bu'],\n",
    "                      title='Confusion matrix, LSH Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual label:  ed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'os'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of similars to return\n",
    "num_similars = 15\n",
    "test_item = 9\n",
    "text = df_test['clean_comp_nouns'][test_item]\n",
    "df_my_test_mod = predict(text,df_train,permutations,num_similars,forest)\n",
    "print('actual label: ',df_test['label'][test_item])\n",
    "df_my_test_mod['label'].value_counts()[:1].index.tolist()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
