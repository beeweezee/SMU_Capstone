{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import model_report as mr\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('C:\\\\Users\\\\blgai\\\\OneDrive\\\\Documents\\\\School\\\\SMU\\\\Courses\\\\Fall 2021\\\\Capstone A\\Data\\\\train_comp_nouns_v1.csv')\n",
    "df_test = pd.read_csv('C:\\\\Users\\\\blgai\\\\OneDrive\\\\Documents\\\\School\\\\SMU\\\\Courses\\\\Fall 2021\\\\Capstone A\\Data\\\\test_comp_nouns_v1.csv')\n",
    "df_holdout = pd.read_csv('C:\\\\Users\\\\blgai\\\\OneDrive\\\\Documents\\\\School\\\\SMU\\\\Courses\\\\Fall 2021\\\\Capstone A\\Data\\\\holdout_comp_nouns_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "X_train = df_train['clean_comp_nouns']\n",
    "y_train = df_train['category']\n",
    "\n",
    "#test data\n",
    "X_test = df_test['clean_comp_nouns']\n",
    "y_test = df_test['category']\n",
    "\n",
    "#holdout data\n",
    "X_holdout = df_holdout['clean_comp_nouns']\n",
    "y_holdout = df_holdout['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    my_accuracy = np.round(metrics.accuracy_score(true_labels,predicted_labels),4)\n",
    "    my_precision = np.round(metrics.precision_score(true_labels,predicted_labels,average='weighted'),4)\n",
    "    my_TPR = np.round(metrics.recall_score(true_labels,predicted_labels,average='weighted'),4)\n",
    "    my_F1 = np.round(metrics.f1_score(true_labels,predicted_labels,average='weighted'),4)\n",
    "    \n",
    "    return my_accuracy, my_precision, my_TPR, my_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn_relief as relief\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm = LinearSVC(penalty='l2',C=1,class_weight={'dr':8,'sx':10},random_state=1234)\n",
    "\n",
    "feat_select_k = [3200,3500,3800,4100,4400,4700,5000]\n",
    "\n",
    "#build BOW features on train corpus\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=25,max_df=.9, norm=\"l2\",smooth_idf=True)\n",
    "tv_train_features = tv.fit_transform(X_train)\n",
    "#transform test corpus into features\n",
    "tv_test_features = tv.transform(X_test)\n",
    "#transform holdout corpus into features\n",
    "tv_holdout_features = tv.transform(X_holdout)\n",
    "\n",
    "#create an object to collect metrics for comparison\n",
    "data_dict = []\n",
    "\n",
    "#select optimal features, train, test, record metrics\n",
    "for i in feat_select_k:\n",
    "    \n",
    "    #find optimal features of size k\n",
    "    r = relief.ReliefF(n_features=i)\n",
    "    transformed_matrix = r.fit_transform(tv_train_features_array,np.array(y_train))\n",
    "    #create a data frame that includes all features and whether or not they are deemed important by feature_selection\n",
    "    feat_imp = pd.DataFrame(list(zip(tv.get_feature_names(),X_opt.get_support().tolist())),columns = ['Features','Important'])\n",
    "    #Now we can grab the important features so that we can select only the important features from the sparse matrix created by TfidfVectorizer\n",
    "    imp_Feats_array = np.array(feat_imp[feat_imp.Important == True].index)\n",
    "    #Now we can pull only the important features out of the original train, test, and holdout matrices\n",
    "    tv_train_features_sub = tv_train_features[:,imp_Feats_array]\n",
    "    tv_test_features_sub = tv_test_features[:,imp_Feats_array]\n",
    "    tv_holdout_features_sub = tv_holdout_features[:,imp_Feats_array]\n",
    "    \n",
    "    #train model using only the optimal features\n",
    "    svm.fit(tv_train_features_sub,y_train)\n",
    "    #get efficacy metrics of trained model\n",
    "    svm_tfidf_cv_scores = cross_val_score(svm,tv_train_features_sub,y_train,cv=5)\n",
    "    svm_tfidf_cv_mean_score = np.mean(svm_tfidf_cv_scores)\n",
    "    svm_tfidf_test_score = svm.score(tv_test_features_sub,y_test)\n",
    "    svm_predictions = svm.predict(tv_test_features_sub)\n",
    "    \n",
    "    accuracy, precision, tpr, f1 = get_metrics(true_labels=y_test,predicted_labels=svm_predictions)\n",
    "    \n",
    "    #store metrics in dictionary\n",
    "    tmp_dict = {'No_Features':i,\n",
    "                'Model':'SVM',\n",
    "                'Class_Weights':'dr:8 and sx:10',\n",
    "                'tfidf_mindf':25,\n",
    "                'tfidf_maxdf':.9,\n",
    "                'cv_5_mean_acc':svm_tfidf_cv_mean_score,\n",
    "                'test_acc':accuracy,\n",
    "                'precision':precision,\n",
    "                'TPR/Recall':tpr,\n",
    "                'F1 Score':f1\n",
    "               }\n",
    "    #append metrics from latest model to dictionary object\n",
    "    data_dict.append(tmp_dict)\n",
    "\n",
    "#create dataframe from dictionary object\n",
    "df_overall = pd.DataFrame(data_dict)\n",
    "\n",
    "#view all metrics\n",
    "df_overall  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_features_array = tv_train_features.toarray()\n",
    "tv_test_features_array = tv_test_features.toarray()\n",
    "tv_holdout_features_array = tv_holdout_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29302, 4100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm = LinearSVC(penalty='l2',C=1,class_weight={'dr':8,'sx':10},random_state=1234)\n",
    "\n",
    "feat_select_k = [3200,3500,3800,4100,4400,4700,5000]\n",
    "\n",
    "#build BOW features on train corpus\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=25,max_df=.9, norm=\"l2\",smooth_idf=True)\n",
    "tv_train_features = tv.fit_transform(X_train)\n",
    "#transform test corpus into features\n",
    "tv_test_features = tv.transform(X_test)\n",
    "#transform holdout corpus into features\n",
    "tv_holdout_features = tv.transform(X_holdout)\n",
    "\n",
    "X_opt=SelectKBest(chi2, k=4100)\n",
    "tv_train_features_trimmed = X_opt.fit_transform(tv_train_features, y_train)\n",
    "tv_train_features_trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data frame that includes all features and whether or not they are deemed important by feature_selection\n",
    "feat_imp = pd.DataFrame(list(zip(tv.get_feature_names(),X_opt.get_support().tolist())),columns = ['Features','Important'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can grab the important features so that we can select only the important features from the sparse matrix created by TfidfVectorizer\n",
    "imp_Feats_array = np.array(feat_imp[feat_imp.Important == True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can pull only the important features out of the original train, test, and holdout matrices\n",
    "tv_train_features_sub = tv_train_features[:,imp_Feats_array]\n",
    "tv_test_features_sub = tv_test_features[:,imp_Feats_array]\n",
    "tv_holdout_features_sub = tv_holdout_features[:,imp_Feats_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train_features_sub_array = tv_train_features_sub.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_relief as relief\n",
    "r = relief.ReliefF(n_features=50)\n",
    "transformed_matrix = r.fit_transform(tv_train_features_sub_array,np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(penalty='l2',C=1,class_weight={'dr':8,'sx':10},random_state=1234)\n",
    "scm.fit(tv_train_features_sub,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = relief.ReliefF(n_features=50)\n",
    "transformed_matrix = r.fit_transform(tv_train_features_array,np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(transformed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=1.0, class_weight={'dr':8,'sx':10},random_state=1234)\n",
    "tmp = sparse.csr_matrix(tv_train_features_array)\n",
    "clf.fit(tmp,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tv_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tv_train_features_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "type(sparse.csr_matrix(tv_train_features_array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
