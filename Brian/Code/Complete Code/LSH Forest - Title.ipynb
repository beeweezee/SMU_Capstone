{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datasketch import MinHash, MinHashLSHForest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import model_report as mr\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = \"C:\\\\Users\\\\blgai\\\\OneDrive\\\\Documents\\\\School\\\\SMU\\\\Courses\\\\Fall 2021\\\\Capstone A\\Data\\\\cleaned_chunked_v2.csv\"\n",
    "df = pd.read_csv(file_info, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance classes\n",
    "g = df.groupby('category')\n",
    "df = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>key_words</th>\n",
       "      <th>content</th>\n",
       "      <th>combined</th>\n",
       "      <th>nouns</th>\n",
       "      <th>compounds</th>\n",
       "      <th>comp_nouns</th>\n",
       "      <th>flat_comp_nouns</th>\n",
       "      <th>clean_comp_nouns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bu</th>\n",
       "      <th>0</th>\n",
       "      <td>*://DECENTLITES.IN</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>DECENT LITES - Home</td>\n",
       "      <td>one of the widely acclaimed companies engaged ...</td>\n",
       "      <td>Home improvement, DECENT LITES, AGRA ROAD, FIR...</td>\n",
       "      <td>DECENT LITES DECENT LITES AGRA ROAD FIROZABAD ...</td>\n",
       "      <td>DECENT LITES - Home one of the widely acclaime...</td>\n",
       "      <td>[('LITES', 7, 12, 'NOUN'), ('Home', 15, 19, 'N...</td>\n",
       "      <td>[('LITES -', 7, 14, 'COMPOUND'), ('DECENTLITES...</td>\n",
       "      <td>{'Xmas', 'stains', 'paragon', 'cracking', 'Chr...</td>\n",
       "      <td>{'Xmas', 'stains', 'paragon', 'cracking', 'Chr...</td>\n",
       "      <td>xmas stain paragon cracking christmas decorati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*://WV.LY</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>Bitly - The Power of the Link</td>\n",
       "      <td>Bitly Brand Tools: Own, understand and activat...</td>\n",
       "      <td>Bitly Brand Tools: Own, understand and activat...</td>\n",
       "      <td>Bitly Product Tour Resources Partners Sign In ...</td>\n",
       "      <td>Bitly - The Power of the Link Bitly Brand Tool...</td>\n",
       "      <td>[('Power', 12, 17, 'PROPN'), ('Link', 25, 29, ...</td>\n",
       "      <td>[('Link Bitly', 25, 35, 'COMPOUND'), ('Brand T...</td>\n",
       "      <td>{'Links Shortened Worldwide Shorten', 'Tech', ...</td>\n",
       "      <td>{'Links Shortened Worldwide Shorten', 'Tech', ...</td>\n",
       "      <td>links shortened worldwide shorten tech e u pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*://AIMRECYCLINGGROUP.COM</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>American Iron &amp; Metal - Accueil</td>\n",
       "      <td>AIM is a Canadian company that recuperates, we...</td>\n",
       "      <td>AIM Recycling USA, AIM Recycling, AIM USA, AIM...</td>\n",
       "      <td>Login Accueil Profil Corporatif La direction H...</td>\n",
       "      <td>American Iron &amp; Metal - Accueil AIM is a Canad...</td>\n",
       "      <td>[('American', 0, 8, 'PROPN'), ('Iron', 9, 13, ...</td>\n",
       "      <td>[('Accueil AIM', 24, 35, 'COMPOUND'), ('scrap ...</td>\n",
       "      <td>{'scrap', 'auto salvage', 'alliages', 'Cuivre'...</td>\n",
       "      <td>{'scrap', 'auto salvage', 'alliages', 'Cuivre'...</td>\n",
       "      <td>scrap auto salvage alliage cuivre weigh maine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*://danforthfilters.com</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>Air Filters &amp; Air Purifiers - Discount Air Fil...</td>\n",
       "      <td>Air Filters &amp; Air Purifiers - Danforth Air Fil...</td>\n",
       "      <td>Air Filters Air Purifiers Danforth Air Filtrat...</td>\n",
       "      <td>Home Air Filters Housings Air Cleaners Air Pur...</td>\n",
       "      <td>Air Filters &amp; Air Purifiers - Discount Air Fil...</td>\n",
       "      <td>[('Air', 0, 3, 'PROPN'), ('Filters', 4, 11, 'P...</td>\n",
       "      <td>[('Air Filters', 0, 11, 'COMPOUND'), ('Air Pur...</td>\n",
       "      <td>{'Filters', 'SiteMap Copyright', 'Experts', 'S...</td>\n",
       "      <td>{'Filters', 'SiteMap Copyright', 'Experts', 'S...</td>\n",
       "      <td>filter sitemap copyright experts supplier air ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*://WWW.SUPERIORSEALANDPAVING.COM</td>\n",
       "      <td>200</td>\n",
       "      <td>bu</td>\n",
       "      <td>en</td>\n",
       "      <td>Superior Seal &amp; Paving</td>\n",
       "      <td>Superior Seal &amp; Paving, Inc is a privately own...</td>\n",
       "      <td>Superior Seal &amp; Paving, Paving in Syracuse, Se...</td>\n",
       "      <td>RSS Search Home About Us Paving Sealing Meet o...</td>\n",
       "      <td>Superior Seal &amp; Paving Superior Seal &amp; Paving,...</td>\n",
       "      <td>[('Superior', 0, 8, 'PROPN'), ('Seal', 9, 13, ...</td>\n",
       "      <td>[('Superior Seal', 0, 13, 'COMPOUND'), ('Super...</td>\n",
       "      <td>{'year', 'Team', 'Fayetteville', 'phases', 'CH...</td>\n",
       "      <td>{'year', 'Team', 'Fayetteville', 'phases', 'CH...</td>\n",
       "      <td>year team fayetteville phase christine receipt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          url  code category language  \\\n",
       "category                                                                \n",
       "bu       0                 *://DECENTLITES.IN   200       bu       en   \n",
       "         1                          *://WV.LY   200       bu       en   \n",
       "         2          *://AIMRECYCLINGGROUP.COM   200       bu       en   \n",
       "         3            *://danforthfilters.com   200       bu       en   \n",
       "         4  *://WWW.SUPERIORSEALANDPAVING.COM   200       bu       en   \n",
       "\n",
       "                                                        title  \\\n",
       "category                                                        \n",
       "bu       0                                DECENT LITES - Home   \n",
       "         1                      Bitly - The Power of the Link   \n",
       "         2                    American Iron & Metal - Accueil   \n",
       "         3  Air Filters & Air Purifiers - Discount Air Fil...   \n",
       "         4                             Superior Seal & Paving   \n",
       "\n",
       "                                                      summary  \\\n",
       "category                                                        \n",
       "bu       0  one of the widely acclaimed companies engaged ...   \n",
       "         1  Bitly Brand Tools: Own, understand and activat...   \n",
       "         2  AIM is a Canadian company that recuperates, we...   \n",
       "         3  Air Filters & Air Purifiers - Danforth Air Fil...   \n",
       "         4  Superior Seal & Paving, Inc is a privately own...   \n",
       "\n",
       "                                                    key_words  \\\n",
       "category                                                        \n",
       "bu       0  Home improvement, DECENT LITES, AGRA ROAD, FIR...   \n",
       "         1  Bitly Brand Tools: Own, understand and activat...   \n",
       "         2  AIM Recycling USA, AIM Recycling, AIM USA, AIM...   \n",
       "         3  Air Filters Air Purifiers Danforth Air Filtrat...   \n",
       "         4  Superior Seal & Paving, Paving in Syracuse, Se...   \n",
       "\n",
       "                                                      content  \\\n",
       "category                                                        \n",
       "bu       0  DECENT LITES DECENT LITES AGRA ROAD FIROZABAD ...   \n",
       "         1  Bitly Product Tour Resources Partners Sign In ...   \n",
       "         2  Login Accueil Profil Corporatif La direction H...   \n",
       "         3  Home Air Filters Housings Air Cleaners Air Pur...   \n",
       "         4  RSS Search Home About Us Paving Sealing Meet o...   \n",
       "\n",
       "                                                     combined  \\\n",
       "category                                                        \n",
       "bu       0  DECENT LITES - Home one of the widely acclaime...   \n",
       "         1  Bitly - The Power of the Link Bitly Brand Tool...   \n",
       "         2  American Iron & Metal - Accueil AIM is a Canad...   \n",
       "         3  Air Filters & Air Purifiers - Discount Air Fil...   \n",
       "         4  Superior Seal & Paving Superior Seal & Paving,...   \n",
       "\n",
       "                                                        nouns  \\\n",
       "category                                                        \n",
       "bu       0  [('LITES', 7, 12, 'NOUN'), ('Home', 15, 19, 'N...   \n",
       "         1  [('Power', 12, 17, 'PROPN'), ('Link', 25, 29, ...   \n",
       "         2  [('American', 0, 8, 'PROPN'), ('Iron', 9, 13, ...   \n",
       "         3  [('Air', 0, 3, 'PROPN'), ('Filters', 4, 11, 'P...   \n",
       "         4  [('Superior', 0, 8, 'PROPN'), ('Seal', 9, 13, ...   \n",
       "\n",
       "                                                    compounds  \\\n",
       "category                                                        \n",
       "bu       0  [('LITES -', 7, 14, 'COMPOUND'), ('DECENTLITES...   \n",
       "         1  [('Link Bitly', 25, 35, 'COMPOUND'), ('Brand T...   \n",
       "         2  [('Accueil AIM', 24, 35, 'COMPOUND'), ('scrap ...   \n",
       "         3  [('Air Filters', 0, 11, 'COMPOUND'), ('Air Pur...   \n",
       "         4  [('Superior Seal', 0, 13, 'COMPOUND'), ('Super...   \n",
       "\n",
       "                                                   comp_nouns  \\\n",
       "category                                                        \n",
       "bu       0  {'Xmas', 'stains', 'paragon', 'cracking', 'Chr...   \n",
       "         1  {'Links Shortened Worldwide Shorten', 'Tech', ...   \n",
       "         2  {'scrap', 'auto salvage', 'alliages', 'Cuivre'...   \n",
       "         3  {'Filters', 'SiteMap Copyright', 'Experts', 'S...   \n",
       "         4  {'year', 'Team', 'Fayetteville', 'phases', 'CH...   \n",
       "\n",
       "                                              flat_comp_nouns  \\\n",
       "category                                                        \n",
       "bu       0  {'Xmas', 'stains', 'paragon', 'cracking', 'Chr...   \n",
       "         1  {'Links Shortened Worldwide Shorten', 'Tech', ...   \n",
       "         2  {'scrap', 'auto salvage', 'alliages', 'Cuivre'...   \n",
       "         3  {'Filters', 'SiteMap Copyright', 'Experts', 'S...   \n",
       "         4  {'year', 'Team', 'Fayetteville', 'phases', 'CH...   \n",
       "\n",
       "                                             clean_comp_nouns  \n",
       "category                                                       \n",
       "bu       0  xmas stain paragon cracking christmas decorati...  \n",
       "         1  links shortened worldwide shorten tech e u pro...  \n",
       "         2  scrap auto salvage alliage cuivre weigh maine ...  \n",
       "         3  filter sitemap copyright experts supplier air ...  \n",
       "         4  year team fayetteville phase christine receipt...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "bu    1595\n",
       "dr    1595\n",
       "ed    1595\n",
       "mk    1595\n",
       "os    1595\n",
       "sp    1595\n",
       "sx    1595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(df.category).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7812,), (2236,), (1117,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#get 10% holdout set\n",
    "train_corpus, holdout_corpus, train_label, holdout_label = train_test_split(df['title'], \n",
    "                                                                           df['category'],\n",
    "                                                                           test_size=.10,random_state=1234)\n",
    "\n",
    "#get 80% train and 20% test sets\n",
    "train_corpus, test_corpus, train_label, test_label = train_test_split(train_corpus,\n",
    "                                                                      train_label,\n",
    "                                                                      test_size=.2225,random_state=1234) #.9 * .2225 = .20\n",
    "\n",
    "train_corpus.shape, test_corpus.shape, holdout_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(zip(train_corpus,train_label),columns=[\"title\",\"label\"])\n",
    "df_test = pd.DataFrame(zip(test_corpus,test_label),columns=[\"title\",\"label\"])\n",
    "df_holdout = pd.DataFrame(zip(holdout_corpus,holdout_label),columns=[\"title\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLUE CORP - The Innovative Thinking</td>\n",
       "      <td>bu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Modded Controllers for Xbox and PlayStation | ...</td>\n",
       "      <td>os</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niall Scully Photography | Wedding Photographe...</td>\n",
       "      <td>mk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Increase Sales Force Effectiveness | Precallpr...</td>\n",
       "      <td>bu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Management in Practice: Practical Plan...</td>\n",
       "      <td>bu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title label\n",
       "0                BLUE CORP - The Innovative Thinking    bu\n",
       "1  Modded Controllers for Xbox and PlayStation | ...    os\n",
       "2  Niall Scully Photography | Wedding Photographe...    mk\n",
       "3  Increase Sales Force Effectiveness | Precallpr...    bu\n",
       "4  Project Management in Practice: Practical Plan...    bu"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Permutations\n",
    "permutations = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    tokens = text.lower()\n",
    "    tokens = tokens.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forest(data,perms):\n",
    "    start_time = time.time()\n",
    "    minhash = []\n",
    "    for text in data['title']:\n",
    "        tokens = preprocess(text)\n",
    "        m = MinHash(num_perm=perms)\n",
    "        for s in tokens:\n",
    "            m.update(s.encode('utf8'))\n",
    "        minhash.append(m)\n",
    "        \n",
    "    forest = MinHashLSHForest(num_perm=perms)\n",
    "    \n",
    "    for i,m in enumerate(minhash):\n",
    "        forest.add(i,m)\n",
    "    \n",
    "    forest.index()\n",
    "    \n",
    "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(list1,list2):\n",
    "    from collections import Counter\n",
    "\n",
    "    # count word occurrences\n",
    "    a_vals = Counter(list1)\n",
    "    b_vals = Counter(list2)\n",
    "\n",
    "    # convert to word-vectors\n",
    "    words  = list(a_vals.keys() | b_vals.keys())\n",
    "    a_vect = [a_vals.get(word, 0) for word in words]        \n",
    "    b_vect = [b_vals.get(word, 0) for word in words]        \n",
    "\n",
    "    # find cosine\n",
    "    len_a  = sum(av*av for av in a_vect) ** 0.5             \n",
    "    len_b  = sum(bv*bv for bv in b_vect) ** 0.5             \n",
    "    dot    = sum(av*bv for av,bv in zip(a_vect, b_vect))    \n",
    "    cosine = dot / (len_a * len_b)                          \n",
    "    \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(test_item, database, perms, num_results, forest):\n",
    "        \n",
    "    tokens = preprocess(test_item)\n",
    "    m = MinHash(num_perm=perms)\n",
    "    for s in tokens:\n",
    "        m.update(s.encode('utf8'))\n",
    "    \n",
    "    idx_array = np.array(forest.query(m, num_results))\n",
    "    if len(idx_array) == 0:\n",
    "        return None #if query is empty, return none\n",
    "    \n",
    "    #label = database.iloc[idx_array]['label']\n",
    "    #text = database.iloc[idx_array]['clean_comp_nouns']\n",
    "    df_results = pd.DataFrame(database.iloc[idx_array][['title','label']])\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_item, database, perms, num_results, forest):\n",
    "    df_pred = get_similars(test_item,df_train,permutations,num_similars,forest)\n",
    "    df_pred['cos_dist'] = df_pred.apply(lambda x: get_cosine(preprocess(x['title']),text),axis=1)\n",
    "    \n",
    "    return df_pred.sort_values('cos_dist',ascending=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(test_item, database, perms, num_results, forest):\n",
    "    df_pred_one = predict(test_item, database, perms, num_results, forest)\n",
    "    #get most similar item based on cosine distance\n",
    "    cat = None\n",
    "    try:\n",
    "        cat = df_pred_one.iloc[1, 1]\n",
    "    except:\n",
    "        cat = 'ed'\n",
    "    \n",
    "    return cat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mod(test_item, database, perms, num_results, forest):\n",
    "    label = None\n",
    "    try:\n",
    "        df_pred_mod = get_similars(test_item,df_train,permutations,num_similars,forest)\n",
    "        label = df_pred_mod['label'].value_counts()[:1].index.tolist()[0]\n",
    "    except:\n",
    "        return None\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 16.064402103424072 seconds to build forest.\n"
     ]
    }
   ],
   "source": [
    "#build lsh forest using training data\n",
    "forest = get_forest(df_train,permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual label:  ed\n",
      "mod similar:  bu\n",
      "closest similar:  sp\n",
      "All similars:                                                    title label  cos_dist\n",
      "5248  hamsterclicks.com : Welcome To hamsterclicks.com!    mk       0.0\n",
      "3679                                  WELCOME RACE FANS    sp       0.0\n",
      "2370                   Welcome to Magazine Rewards Plus    mk       0.0\n",
      "707                                            WELCOME!    ed       0.0\n",
      "4036             :: Welcome to Bulkbag Manufacturers ::    bu       0.0\n",
      "4167                Welcome to Ugborough Primary School    ed       0.0\n",
      "7118                Welcome to the HENNEPDESK Community    dr       0.0\n",
      "2256                     Welcome to The Power Kite Site    sp       0.0\n",
      "4437       Welcome to The Linde Group | The Linde Group    bu       0.0\n",
      "5210                                 Isprojects Welcome    mk       0.0\n",
      "5085                         Welcome To SpankingDVD.com    sx       0.0\n",
      "4317                          Welcome to COCKSUCKERS.TV    sx       0.0\n",
      "7011                            Welcome to PetKraze.com    mk       0.0\n",
      "4102  Welcome to Landracing.com Welcome to the Front...    sp       0.0\n",
      "6502                                  Welcome to WASATO    bu       0.0\n",
      "4711                   Welcome to Marymount University!    ed       0.0\n",
      "2406                     Welcome to Companion Care Vets    mk       0.0\n",
      "6503                        Welcome to Al Jedar Trading    bu       0.0\n",
      "4079                                    Welcome Welcome    bu       0.0\n",
      "6512                                            Welcome    ed       0.0\n",
      "4593                   Welcome to Swansea Public School    ed       0.0\n",
      "2674                 Welcome to Revolutionary Marketing    bu       0.0\n",
      "6390                                            Welcome    ed       0.0\n",
      "6008             Powerup - Welcome to Powerup Sdn. Bhd.    bu       0.0\n",
      "2241                            JQY: Welcome to JQYouth    bu       0.0\n",
      "6464       Welcome to The Linde Group | The Linde Group    mk       0.0\n",
      "1086           Welcome To Zeolyst International Website    bu       0.0\n",
      "2878               aviation.ch - Welcome to aviation.ch    ed       0.0\n",
      "5768  Welcome To Greenbuild International Conference...    bu       0.0\n",
      "6668                            Welcome to Laois Sports    sp       0.0\n",
      "2063                         Welcome to St Mary's Calne    ed       0.0\n",
      "7183                    Welcome to Doyle Electric, Inc.    bu       0.0\n",
      "2715                                    Welcome Welcome    sp       0.0\n",
      "1182                                          Welcome -    mk       0.0\n",
      "4386                                ENC PRESS: Welcome!    os       0.0\n",
      "6565                           Welcome to AlexaDoll.com    sx       0.0\n",
      "2552  Hot tube man:: Hot Gays Porn Welcome to Menonl...    sx       0.0\n",
      "2089                          Welcome to TeenWebcams.in    sx       0.0\n",
      "2473  Flags International | Welcome To Flags Interna...    os       0.0\n",
      "2731              Welcome to The Bythams Primary School    ed       0.0\n",
      "3244               Welcome to Christiansburg Institiute    ed       0.0\n",
      "5160                          Welcome to Captain Boner!    sx       0.0\n",
      "1451  Welcome to Bromhead Johnson - Bromhead Johnson...    bu       0.0\n",
      "7087    Welcome To Indus International Community School    ed       0.0\n",
      "2866                        Welcome to Tunnelfind.co.za    bu       0.0\n",
      "3891                    General Produce, Inc. - Welcome    bu       0.0\n",
      "3124                           Welcome to Prinzzess VIP    sx       0.0\n",
      "4916                                            Welcome    bu       0.0\n",
      "7606                            Welcome | Expert Alumni    bu       0.0\n",
      "1405             Welcome to Middle College High School!    ed       0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Welcome to TallTrees Montessori-inspired School!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of similars to return\n",
    "num_similars = 50\n",
    "test_item = 5\n",
    "text = df_test['title'][test_item]\n",
    "#query the forest\n",
    "df_predict = predict(text,df_train,permutations,num_similars,forest)\n",
    "print('actual label: ',df_test['label'][test_item])\n",
    "print('mod similar: ',predict_mod(text,df_train,permutations,num_similars,forest))\n",
    "print('closest similar: ',predict_one(text,df_train,permutations,num_similars,forest))\n",
    "print('All similars: ',predict(text,df_train,permutations,num_similars,forest))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(list(zip(df_test['title'],df_test['label'])),columns=['terms','category'])\n",
    "df_results['lsh_predict'] = df_results.apply(lambda x: predict_mod(x['terms'],df_train,permutations,num_similars,forest),axis=1)\n",
    "df_results['match'] = np.where(df_results['category']==df_results['lsh_predict'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>category</th>\n",
       "      <th>lsh_predict</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saeco Arad &gt; GERA COM &gt; Aparate Cafea - Espresso</td>\n",
       "      <td>bu</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EduQuality EduQuality</td>\n",
       "      <td>ed</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cantiere Nautico - Cranchi</td>\n",
       "      <td>mk</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MavPuck.com</td>\n",
       "      <td>sp</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ShopPal</td>\n",
       "      <td>os</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>http://heartwooddesign.co/millwork/solid-wood-...</td>\n",
       "      <td>mk</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>หน้าหลัก | Mainpage ข้อมูล ข่าวสาร งานวิจัย</td>\n",
       "      <td>ed</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>Verachan</td>\n",
       "      <td>os</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>Skoleporten Rugkobbelskolen Skoleporten - Rugk...</td>\n",
       "      <td>ed</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>Jets Towing Inc. Jets Towing Inc.</td>\n",
       "      <td>mk</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  terms category lsh_predict  \\\n",
       "3      Saeco Arad > GERA COM > Aparate Cafea - Espresso       bu        None   \n",
       "9                                 EduQuality EduQuality       ed        None   \n",
       "18                           Cantiere Nautico - Cranchi       mk        None   \n",
       "20                                          MavPuck.com       sp        None   \n",
       "39                                              ShopPal       os        None   \n",
       "...                                                 ...      ...         ...   \n",
       "2146  http://heartwooddesign.co/millwork/solid-wood-...       mk        None   \n",
       "2147        หน้าหลัก | Mainpage ข้อมูล ข่าวสาร งานวิจัย       ed        None   \n",
       "2160                                           Verachan       os        None   \n",
       "2190  Skoleporten Rugkobbelskolen Skoleporten - Rugk...       ed        None   \n",
       "2193                  Jets Towing Inc. Jets Towing Inc.       mk        None   \n",
       "\n",
       "      match  \n",
       "3         0  \n",
       "9         0  \n",
       "18        0  \n",
       "20        0  \n",
       "39        0  \n",
       "...     ...  \n",
       "2146      0  \n",
       "2147      0  \n",
       "2160      0  \n",
       "2190      0  \n",
       "2193      0  \n",
       "\n",
       "[109 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['lsh_predict'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalSamples': 2236,\n",
       " 'overallAccuracy': 0.5380143112701252,\n",
       " 'byCategory': {'dr': {'totalSamples': 331, 'accuracy': 0.7280966767371602},\n",
       "  'sx': {'totalSamples': 332, 'accuracy': 0.713855421686747},\n",
       "  'ed': {'totalSamples': 330, 'accuracy': 0.5151515151515151},\n",
       "  'sp': {'totalSamples': 318, 'accuracy': 0.5031446540880503},\n",
       "  'os': {'totalSamples': 314, 'accuracy': 0.45222929936305734},\n",
       "  'bu': {'totalSamples': 311, 'accuracy': 0.42443729903536975},\n",
       "  'mk': {'totalSamples': 300, 'accuracy': 0.4033333333333333}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpt = mr.generate_report(df_results)\n",
    "rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-31c5fbd9293d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcnf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lsh_predict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'os'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ed'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mk'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Plot non-normalized confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \"\"\"\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'multiclass'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[1;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(df_results['category'],df_results['lsh_predict'],labels=['os','ed','dr','sp','mk','sx','bu'])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "mr.plot_confusion_matrix(cnf_matrix, classes=['os','ed','dr','sp','mk','sx','bu'],\n",
    "                      title='Confusion matrix, LSH Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of similars to return\n",
    "num_similars = 15\n",
    "test_item = 9\n",
    "text = df_test['title'][test_item]\n",
    "df_my_test_mod = predict(text,df_train,permutations,num_similars,forest)\n",
    "print('actual label: ',df_test['label'][test_item])\n",
    "df_my_test_mod['label'].value_counts()[:1].index.tolist()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
